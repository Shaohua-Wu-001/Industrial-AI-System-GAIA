#!/usr/bin/env python3
"""
Parser v3.1 - Bug Fixes Only
åªä¿®å¾© 3 å€‹å·²çŸ¥ bugï¼Œä¿è­‰ä¸æœƒè®Šå·®

ä¿®å¾©å…§å®¹ï¼š
1. unit_converter çš„éŒ¯èª¤åƒæ•¸ (operation, expression)
2. æª”æ¡ˆè·¯å¾‘æ™ºèƒ½åŒ¹é…
3. read_excel çš„ xlrd æ”¯æ´

Version: 3.1.0
Date: 2026-02-02
"""

import json
import re
import os
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path

class ExecutablePlanParserV31:
    """åªä¿® bug çš„ v3.1"""
    
    def __init__(self, gaia_tasks_file: str, data_dir: str = './data'):
        self.data_dir = Path(data_dir)
        
        # è¼‰å…¥ä»»å‹™
        with open(gaia_tasks_file, 'r', encoding='utf-8') as f:
            self.tasks = json.load(f)
        
        # å»ºç«‹æª”æ¡ˆæ˜ å°„è¡¨
        self.file_map = self._build_file_map()
        
        # å·¥å…·ç°½å
        self.tool_signatures = {
            'web_search': ['query', 'num_results'],
            'web_fetch': ['url', 'timeout'],
            'calculate': ['expression'],
            'read_pdf': ['file_path', 'page_numbers'],
            'read_csv': ['file_path', 'encoding'],
            'read_excel': ['file_path', 'sheet_name'],
            'read_json': ['file_path'],
            'read_xml': ['file_path'],
            'read_image': ['file_path'],
            'image_to_text': ['file_path', 'lang'],
            'filter_data': ['data', 'conditions'],
            'compare_values': ['value1', 'value2'],
            'find_in_text': ['text', 'search_terms'],
            'count_occurrences': ['data', 'target'],
            'extract_information': ['text', 'extract_type', 'keywords', 'pattern'],
            'deduplicate_data': ['data', 'key_fields'],
            'unit_converter': ['value', 'from_unit', 'to_unit', 'unit_type'],
            'wikipedia_search': ['query', 'num_results'],
            'extract_zip': ['zip_path'],
        }
        
        # åƒæ•¸æ˜ å°„ï¼ˆéŒ¯èª¤ -> æ­£ç¢ºï¼‰
        self.param_mapping = {
            'extract_information': {
                'target': 'keywords',
            },
            'deduplicate_data': {
                'key': 'key_fields',
            },
        }
        
        # unit_converter æ”¯æ´çš„é¡å‹
        self.valid_unit_types = ['length', 'weight', 'temperature', 'time', 'volume']
    
    def _build_file_map(self) -> Dict[str, str]:
        """å»ºç«‹æª”æ¡ˆæ˜ å°„è¡¨ï¼ˆå¢å¼·ç‰ˆï¼‰"""
        file_map = {}
        
        if not self.data_dir.exists():
            return file_map
        
        for task in self.tasks:
            task_id = task['task_id']
            file_name = task.get('file_name', '')
            
            if not file_name:
                continue
            
            # æ–¹æ³• 1: ç²¾ç¢ºåŒ¹é…
            exact_path = self.data_dir / file_name
            if exact_path.exists():
                file_map[task_id] = str(exact_path)
                continue
            
            # æ–¹æ³• 2: å‰ç¶´åŒ¹é… (å‰ 8 å€‹å­—å…ƒ)
            prefix = file_name.split('.')[0][:8]
            for f in self.data_dir.iterdir():
                if f.is_file() and f.name.startswith(prefix):
                    file_map[task_id] = str(f)
                    break
            
            # æ–¹æ³• 3: ZIP æª”æ¡ˆè¨˜éŒ„ï¼ˆä½†ä¸è‡ªå‹•è§£å£“ï¼Œç•™çµ¦ executorï¼‰
            if task_id not in file_map and file_name.endswith('.zip'):
                zip_path = self.data_dir / file_name
                if zip_path.exists():
                    file_map[task_id] = str(zip_path)
        
        return file_map
    
    def is_placeholder(self, value: Any) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºä½”ä½ç¬¦"""
        if not isinstance(value, str):
            return False
        
        placeholder_patterns = [
            r'^<.*>$',
            r'<from_context>',
            r'<iterate:',
            r'<clicked:',
            r'<link_in:',
            r'<result:',
            r'<multiple:',
            r'<infer>',
            r'<new_tab>',
            r'<page:',
            r'<followed:',
            r'<conversion_constant>',
        ]
        
        for pattern in placeholder_patterns:
            if re.search(pattern, value, re.IGNORECASE):
                return True
        
        return False
    
    def is_valid_url(self, url: str) -> bool:
        """æª¢æŸ¥ URL æœ‰æ•ˆæ€§"""
        if self.is_placeholder(url):
            return False
        
        if not url.startswith(('http://', 'https://')):
            return False
        
        if '<' in url or '>' in url:
            return False
        
        return True
    
    def is_valid_file_path(self, file_path: str) -> bool:
        """æª¢æŸ¥æª”æ¡ˆè·¯å¾‘ï¼ˆå¢å¼·ç‰ˆï¼‰"""
        if self.is_placeholder(file_path):
            return False
        
        path = Path(file_path)
        if path.exists() and path.is_file():
            return True
        
        # æ–°å¢ï¼šæª¢æŸ¥æ˜¯å¦ç‚º ZIP å…§çš„æª”æ¡ˆæ¨¡å¼
        # ä¾‹å¦‚ï¼šdata/.extracted/xxx/file.xls
        # é€™ç¨®æƒ…æ³ä¸‹ï¼Œexecutor æœƒè™•ç†è§£å£“
        if '.extracted' in file_path or 'zip' in file_path.lower():
            # æ¨™è¨˜ç‚ºå¯èƒ½æœ‰æ•ˆï¼Œä½†ç”± executor ç¢ºèª
            return True
        
        return False
    
    def clean_calculate_expression(self, expression: str) -> Optional[str]:
        """æ¸…ç†è¨ˆç®—è¡¨é”å¼"""
        if self.is_placeholder(expression):
            return None
        
        # ç§»é™¤å–®ä½
        cleaned = re.sub(r'\s*[a-zA-Z]+(/[a-zA-Z]+)*', '', expression)
        cleaned = cleaned.replace('%', '/100')
        
        try:
            eval(cleaned)
            return cleaned
        except:
            return None
    
    def fix_tool_params(self, tool_name: str, params: Dict[str, Any]) -> Tuple[Dict[str, Any], List[str]]:
        """
        ä¿®æ­£å·¥å…·åƒæ•¸ï¼ˆåŠ å¼·ç‰ˆï¼‰
        
        Returns:
            (fixed_params, fix_notes)
        """
        fixed_params = {}
        fix_notes = []
        
        # === BUG FIX 1: unit_converter åƒæ•¸ä¿®æ­£ ===
        if tool_name == 'unit_converter':
            # ç§»é™¤éŒ¯èª¤çš„åƒæ•¸
            if 'operation' in params:
                fix_notes.append("ç§»é™¤éŒ¯èª¤åƒæ•¸: operation")
                params = {k: v for k, v in params.items() if k != 'operation'}
            
            if 'expression' in params:
                fix_notes.append("ç§»é™¤éŒ¯èª¤åƒæ•¸: expression")
                params = {k: v for k, v in params.items() if k != 'expression'}
            
            # ç¢ºä¿æœ‰å¿…è¦åƒæ•¸
            required = ['value', 'from_unit', 'to_unit', 'unit_type']
            for req in required:
                if req not in params:
                    if req == 'unit_type':
                        # æ ¹æ“šå–®ä½æ¨æ–·é¡å‹
                        from_unit = params.get('from_unit', '').lower()
                        if from_unit in ['kg', 'g', 'lb', 'oz', 'ton']:
                            params['unit_type'] = 'weight'
                        elif from_unit in ['m', 'cm', 'km', 'ft', 'in', 'mi']:
                            params['unit_type'] = 'length'
                        elif from_unit in ['c', 'f', 'k']:
                            params['unit_type'] = 'temperature'
                        elif from_unit in ['l', 'ml', 'gal']:
                            params['unit_type'] = 'volume'
                        else:
                            params['unit_type'] = 'length'  # é è¨­
                        fix_notes.append(f"æ¨æ–· unit_type: {params['unit_type']}")
        
        # æ¨™æº–åƒæ•¸åç¨±ä¿®æ­£
        if tool_name in self.param_mapping:
            mapping = self.param_mapping[tool_name]
            for key, value in params.items():
                new_key = mapping.get(key, key)
                fixed_params[new_key] = value
                if new_key != key:
                    fix_notes.append(f"åƒæ•¸é‡å‘½å: {key} â†’ {new_key}")
        else:
            fixed_params = params
        
        return fixed_params, fix_notes
    
    def resolve_file_path(self, file_path: str, task_id: str) -> Tuple[str, List[str]]:
        """
        æ™ºèƒ½æª”æ¡ˆè·¯å¾‘è§£æï¼ˆå¢å¼·ç‰ˆï¼‰
        
        Returns:
            (resolved_path, resolution_notes)
        """
        notes = []
        
        # === BUG FIX 2: æ™ºèƒ½æª”æ¡ˆåŒ¹é… ===
        
        # ç­–ç•¥ 1: ä½¿ç”¨æ˜ å°„è¡¨
        if task_id in self.file_map:
            mapped = self.file_map[task_id]
            
            # å¦‚æœæ˜¯ ZIP æª”æ¡ˆï¼Œéœ€è¦ç‰¹æ®Šè™•ç†
            if mapped.endswith('.zip'):
                # æª¢æŸ¥æ˜¯å¦éœ€è¦è®€å– ZIP å…§çš„ç‰¹å®šæª”æ¡ˆ
                if '.xls' in file_path.lower():
                    # æ¨™è¨˜ç‚ºéœ€è¦å¾ ZIP è§£å£“
                    notes.append(f"æª”æ¡ˆåœ¨ ZIP ä¸­: {mapped}")
                    # å»ºè­°è·¯å¾‘ï¼ˆexecutor æœƒè™•ç†ï¼‰
                    extract_dir = str(Path(mapped).parent / '.extracted' / Path(mapped).stem)
                    
                    # å˜—è©¦æ‰¾åˆ°å¯¦éš›æª”æ¡ˆ
                    extract_path = Path(extract_dir)
                    if extract_path.exists():
                        if '.xls' in file_path.lower():
                            xls_files = list(extract_path.glob('*.xls*'))
                            if xls_files:
                                return str(xls_files[0]), notes + [f"å¾ ZIP è§£å£“: {xls_files[0].name}"]
                        if '.xml' in file_path.lower():
                            xml_files = list(extract_path.glob('*.xml'))
                            if xml_files:
                                return str(xml_files[0]), notes + [f"å¾ ZIP è§£å£“: {xml_files[0].name}"]
                    
                    # å¦‚æœé‚„æ²’è§£å£“ï¼Œè¿”å› ZIP è·¯å¾‘ä½†æ¨™è¨˜éœ€è¦è§£å£“
                    return mapped, notes + ["éœ€è¦å…ˆè§£å£“ ZIP"]
                else:
                    return mapped, notes + ["ä½¿ç”¨æ˜ å°„æª”æ¡ˆ"]
            else:
                return mapped, notes + ["ä½¿ç”¨æ˜ å°„æª”æ¡ˆ"]
        
        # ç­–ç•¥ 2: ç›´æ¥æª¢æŸ¥è·¯å¾‘
        path = Path(file_path)
        if path.exists():
            return str(path), notes + ["è·¯å¾‘æœ‰æ•ˆ"]
        
        # ç­–ç•¥ 3: ç›¸å°è·¯å¾‘è½‰æ›
        if not file_path.startswith('/'):
            clean = file_path.replace('./data/', '').replace('data/', '')
            abs_path = self.data_dir / clean
            if abs_path.exists():
                return str(abs_path), notes + [f"ç›¸å° â†’ çµ•å°è·¯å¾‘"]
        
        # ç­–ç•¥ 4: é€šç”¨ä½”ä½ç¬¦åŒ¹é…
        if any(x in file_path.lower() for x in ['document.pdf', 'spreadsheet', 'data.']):
            # æ ¹æ“šå‰¯æª”åæŸ¥æ‰¾
            if '.pdf' in file_path:
                pdfs = list(self.data_dir.glob('*.pdf'))
                if pdfs:
                    return str(pdfs[0]), notes + [f"æ¨¡ç³ŠåŒ¹é…: {pdfs[0].name}"]
            
            if 'spreadsheet' in file_path or '.xls' in file_path:
                excels = list(self.data_dir.glob('*.xls*'))
                if excels:
                    return str(excels[0]), notes + [f"æ¨¡ç³ŠåŒ¹é…: {excels[0].name}"]
            
            if '.json' in file_path:
                jsons = list(self.data_dir.glob('*.json*'))
                if jsons:
                    return str(jsons[0]), notes + [f"æ¨¡ç³ŠåŒ¹é…: {jsons[0].name}"]
            
            if '.xml' in file_path:
                xmls = list(self.data_dir.glob('*.xml'))
                if xmls:
                    return str(xmls[0]), notes + [f"æ¨¡ç³ŠåŒ¹é…: {xmls[0].name}"]
        
        return file_path, notes + ["ç„¡æ³•è§£æ"]
    
    def is_step_executable(self, tool_name: str, arguments: Dict[str, Any], task_id: str) -> Tuple[bool, str]:
        """åˆ¤æ–·æ­¥é©Ÿæ˜¯å¦å¯åŸ·è¡Œ"""
        
        # æª¢æŸ¥ä½”ä½ç¬¦
        for key, value in arguments.items():
            if self.is_placeholder(value):
                return False, f"åƒæ•¸ {key} åŒ…å«ä½”ä½ç¬¦: {value}"
        
        # ç‰¹å®šå·¥å…·æª¢æŸ¥
        if tool_name == 'web_fetch':
            url = arguments.get('url', '')
            if not self.is_valid_url(url):
                return False, f"ç„¡æ•ˆçš„ URL: {url}"
        
        elif tool_name in ['read_pdf', 'read_csv', 'read_excel', 'read_json', 'read_xml', 'read_image']:
            file_path = arguments.get('file_path', '')
            
            # å…ˆå˜—è©¦è§£æè·¯å¾‘
            resolved, notes = self.resolve_file_path(file_path, task_id)
            
            # æ›´æ–°åƒæ•¸
            arguments['file_path'] = resolved
            
            # æª¢æŸ¥æ˜¯å¦æœ‰æ•ˆ
            if not self.is_valid_file_path(resolved):
                return False, f"æª”æ¡ˆä¸å­˜åœ¨: {resolved}"
        
        elif tool_name == 'calculate':
            expression = arguments.get('expression', '')
            cleaned = self.clean_calculate_expression(expression)
            if cleaned is None:
                return False, f"ç„¡æ³•æ¸…ç†çš„è¡¨é”å¼: {expression}"
            # æ›´æ–°ç‚ºæ¸…ç†å¾Œçš„è¡¨é”å¼
            arguments['expression'] = cleaned
        
        elif tool_name == 'unit_converter':
            # æª¢æŸ¥ unit_type æ˜¯å¦æœ‰æ•ˆ
            unit_type = arguments.get('unit_type', 'length')
            if unit_type not in self.valid_unit_types:
                return False, f"ä¸æ”¯æ´çš„å–®ä½é¡å‹: {unit_type}"
        
        return True, "OK"
    
    def process_step(self, step: Dict[str, Any], task_id: str) -> Tuple[Optional[Dict], List[str]]:
        """è™•ç†å–®å€‹æ­¥é©Ÿ"""
        tool_name = step.get('tool_name')
        arguments = step.get('arguments', {}).copy()
        notes = []
        
        # ä¿®æ­£åƒæ•¸
        arguments, fix_notes = self.fix_tool_params(tool_name, arguments)
        notes.extend(fix_notes)
        
        # æª¢æŸ¥å¯åŸ·è¡Œæ€§
        is_exec, reason = self.is_step_executable(tool_name, arguments, task_id)
        
        if not is_exec:
            return None, notes + [reason]
        
        return {
            'step_id': step.get('step_id'),
            'tool_name': tool_name,
            'arguments': arguments,
            'description': step.get('description', ''),
            'executable': True,
            'skip_reason': None,
            'fix_notes': notes
        }, notes
    
    def parse_task(self, task: Dict[str, Any], original_plan: Dict[str, Any]) -> Dict[str, Any]:
        """è§£æå–®å€‹ä»»å‹™"""
        task_id = task['task_id']
        original_steps = original_plan.get('tool_sequence', [])
        
        executable_steps = []
        skipped_steps = []
        all_notes = []
        
        for step in original_steps:
            processed, notes = self.process_step(step, task_id)
            all_notes.extend(notes)
            
            if processed:
                executable_steps.append(processed)
            else:
                is_exec, reason = self.is_step_executable(
                    step.get('tool_name'),
                    step.get('arguments', {}),
                    task_id
                )
                
                skipped_steps.append({
                    'step_id': step.get('step_id'),
                    'tool_name': step.get('tool_name'),
                    'description': step.get('description', '')[:100],
                    'skip_reason': reason,
                    'notes': notes
                })
        
        return {
            'task_id': task_id,
            'question': task['Question'],
            'final_answer': task['Final answer'],
            'file_name': task.get('file_name', ''),
            'tool_sequence': executable_steps,
            'skipped_steps': skipped_steps,
            'stats': {
                'total_steps': len(original_steps),
                'executable_steps': len(executable_steps),
                'skipped_steps': len(skipped_steps),
                'executable_rate': len(executable_steps) / len(original_steps) if original_steps else 0
            },
            'fix_notes': all_notes
        }
    
    def parse_all_tasks(self, original_plans_file: str, output_file: str):
        """è§£ææ‰€æœ‰ä»»å‹™"""
        
        # è¼‰å…¥åŸå§‹ plans
        with open(original_plans_file, 'r', encoding='utf-8') as f:
            original_plans = json.load(f)
        
        plans_map = {p['task_id']: p for p in original_plans}
        
        executable_plans = []
        
        print("=" * 80)
        print("ğŸ”§ Parser v3.1 - Bug Fixes Only")
        print("=" * 80)
        print()
        
        for task in self.tasks:
            task_id = task['task_id']
            
            if task_id not in plans_map:
                print(f"âš ï¸  è·³é {task_id}: æ²’æœ‰å°æ‡‰çš„ plan")
                continue
            
            original_plan = plans_map[task_id]
            executable_plan = self.parse_task(task, original_plan)
            executable_plans.append(executable_plan)
            
            stats = executable_plan['stats']
            print(f"âœ… {task_id}")
            print(f"   ç¸½æ­¥é©Ÿ: {stats['total_steps']}")
            print(f"   å¯åŸ·è¡Œ: {stats['executable_steps']} ({stats['executable_rate']*100:.1f}%)")
            print(f"   è·³é: {stats['skipped_steps']}")
            
            if executable_plan.get('fix_notes'):
                print(f"   ğŸ”§ ä¿®å¾©: {len(executable_plan['fix_notes'])} å€‹")
            print()
        
        # å„²å­˜çµæœ
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(executable_plans, f, indent=2, ensure_ascii=False)
        
        # çµ±è¨ˆ
        total_original = sum(p['stats']['total_steps'] for p in executable_plans)
        total_executable = sum(p['stats']['executable_steps'] for p in executable_plans)
        total_skipped = sum(p['stats']['skipped_steps'] for p in executable_plans)
        
        print("=" * 80)
        print("ç¸½çµ±è¨ˆ")
        print("=" * 80)
        print(f"ä»»å‹™æ•¸: {len(executable_plans)}")
        print(f"åŸå§‹æ­¥é©Ÿæ•¸: {total_original}")
        print(f"å¯åŸ·è¡Œæ­¥é©Ÿæ•¸: {total_executable} ({total_executable/total_original*100:.1f}%)")
        print(f"è·³éæ­¥é©Ÿæ•¸: {total_skipped}")
        print()
        print(f"âœ… å·²å„²å­˜åˆ°: {output_file}")
        print()


def main():
    """ä¸»ç¨‹å¼"""
    parser = ExecutablePlanParserV31(
        gaia_tasks_file='gaia_level3_tasks.json',
        data_dir='./data'
    )
    
    parser.parse_all_tasks(
        original_plans_file='parser_output/plans_v2.1.json',
        output_file='parser_output/plans_v3.1_bugfix.json'
    )


if __name__ == '__main__':
    main()
