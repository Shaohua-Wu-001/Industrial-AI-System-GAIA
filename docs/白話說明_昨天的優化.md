# 白話說明：昨天做了什麼優化？

**日期**：2026-02-09
**目標**：把 GAIA Level 3 的資料處理 pipeline 修到最 solid 的版本

---

## 🎯 簡單來說，做了兩件大事：

### 1. **讓電腦更聽得懂「誰依賴誰」**（改進 Chain-to-DAG）
### 2. **生出更多樣化的訓練資料**（擴充 Data Augmentation）

---

## 📌 第一件事：改進「依賴關係推斷」

### 白話解釋

想像你在做菜：
- **步驟 1**：買菜
- **步驟 2**：洗菜
- **步驟 3**：切菜
- **步驟 4**：炒菜

很明顯：
- 步驟 2（洗菜）依賴步驟 1（買菜）
- 步驟 3（切菜）依賴步驟 2（洗菜）
- 步驟 4（炒菜）依賴步驟 3（切菜）

但如果我只給你一串文字：
```
1. 去市場
2. 處理食材
3. 用刀子
4. 開火
```

你可能不知道誰依賴誰，對吧？

**這就是我們遇到的問題**：Parser 給我們一串工具序列，但沒有明確說「這個工具的輸出會給下個工具用」。

---

### 原本的做法（太笨了）

原本的程式只會：
1. **硬性規定**：每個步驟都依賴前一個步驟
2. **結果**：很多根本不相關的步驟被串在一起

就像把「去市場」和「開火」直接連在一起，但其實中間還有「洗菜」「切菜」。

**數據證明這很糟**：
- 20% 的步驟變成「孤島」（沒人依賴它，它也不依賴別人）
- DAG 的「邊」（連線）只有 26 條

---

### 改進後的做法（聰明多了）

我加了 **4 層推斷規則**，從最精準到最保守：

#### 規則 1：看「佔位符」（Placeholder）
如果步驟的參數寫著：
- `<from_previous_search>` → 去找前面的 `web_search`
- `<from_context>` → 去找前面的 `read_*` 或 `web_fetch`
- `<iterate:name>` → 去找前面產生 `name` 欄位的工具

**白話**：直接看參數裡的「小抄」，告訴你要用哪個步驟的結果。

#### 規則 2：看「參數名稱」
- 如果參數是 `file_path` → 可能依賴前面的 `extract_zip`（解壓縮）
- 如果參數是 `url` → 可能依賴前面的 `web_search`（搜尋）
- 如果參數是 `data` → 可能依賴前面的 `read_*`（讀檔）

**白話**：看參數的「名字」，猜它需要什麼輸入。

#### 規則 3：看「工具語義」
- `calculate`（計算）→ 依賴前面的資料源（`read_*`, `web_fetch`）
- `compare_values`（比較）→ 依賴前面的 `calculate`
- `filter_data`（過濾）→ 依賴前面的 `read_*`

**白話**：根據工具的「意義」，推斷它需要什麼。

#### 規則 4：看「順序」（最後保底）
如果前面 3 個規則都找不到依賴，才用順序：
- 但會排除「起始節點」（如 `web_search`, `read_*`）

**白話**：實在沒辦法了，就假設它依賴前一個步驟。

---

### 改進效果

**數據對比**：

| 指標 | 改進前 | 改進後 | 改善幅度 |
|------|--------|--------|----------|
| DAG 邊數（連線） | 26 | 31 | **+19%** |
| 孤立節點比例 | ~20% | 2.6% | **-87%** |

**白話翻譯**：
- 原本有 20% 的步驟是「孤島」（沒人理它）
- 現在只剩 2.6%（幾乎都連起來了）

---

## 📌 第二件事：擴充「資料增強策略」

### 白話解釋

想像你只有 7 份食譜，但想訓練一個 AI 大廚。

**問題**：樣本太少了！

**解決方法**：從這 7 份食譜「變出」更多版本：
- 把「炒飯」改成「炒麵」（工具替換）
- 把「先切菜再洗菜」（順序重排）
- 把「切菜」拆成「切絲」+「切丁」（分解）
- 把「切菜」+「切肉」合併成「切食材」（合併）

這樣就能從 7 份食譜變出 77 份！

---

### 原本的做法（5 種策略）

1. **Add reasoning step**：插入推理步驟
2. **Remove optional step**：移除可選步驟
3. **Simplify description**：簡化描述
4. **Add subgoal**：加入子目標
5. **Permute parallel steps**：重排平行步驟

**問題**：變化不夠激進，生出的樣本太像原本的。

---

### 改進後的做法（10 種策略）

新增 5 種**更激進**的策略：

#### 策略 6：**Tool Substitution**（工具替換）
**白話**：把 `web_search` 換成 `wikipedia_search`
**效果**：讓 AI 學會「不同工具可以做類似的事」

#### 策略 7：**Reorder**（順序重排）
**白話**：在不違反依賴的前提下，把「步驟 2」和「步驟 3」對調
**效果**：讓 AI 學會「有些步驟可以換順序」

#### 策略 8：**Decompose**（分解）
**白話**：把「計算」拆成「提取資料」+「計算」
**效果**：讓 AI 學會「把複雜步驟拆成小步驟」

#### 策略 9：**Merge Steps**（合併）
**白話**：把 2 個連續的 `web_fetch` 合併成 1 個 batch `web_fetch`
**效果**：讓 AI 學會「把重複步驟合併」

#### 策略 10：**Add Intermediate Output**（標記中間輸出）
**白話**：在 `calculate` 後面加上「儲存中間結果」
**效果**：讓 AI 學會「哪些步驟的結果很重要，要記下來」

---

### 改進效果

**數據對比**：

| 指標 | 改進前 | 改進後 | 改善幅度 |
|------|--------|--------|----------|
| 訓練樣本數 | 42 | 77 | **+83%** |
| 序列多樣性 | 21.4% | 26.0% | **+22%** |
| 平均 planning 步驟 | 5.7 | 5.5 | 維持穩定 |

**白話翻譯**：
- 原本只有 42 份食譜
- 現在有 77 份（多了 83%）
- 而且這些食譜更多樣化（從 21.4% 提升到 26.0%）

---

## 📊 整體改進總結

### 改進前的問題
1. **DAG 太鬆散**：20% 的步驟是孤島
2. **訓練樣本太少**：只有 42 份
3. **多樣性不足**：很多樣本長得太像

### 改進後的成果
1. **DAG 更緊密**：孤島降到 2.6%
2. **訓練樣本更多**：增加到 77 份
3. **多樣性更高**：從 21.4% 提升到 26.0%

---

## 🔧 技術細節（給想深入了解的人）

### 檔案改動

#### `chain_to_dag.py`（Line 139-318）
- 重寫 `_find_dependencies()` 函數
- 新增 4 層推斷規則（+124 行）
- 效果：孤立節點從 20% 降到 2.6%

#### `data_augmentation.py`（新增 5 種變體方法）
- `_variant_tool_substitution()`：工具替換
- `_variant_reorder()`：順序重排
- `_variant_decompose()`：分解步驟
- `_variant_merge_steps()`：合併步驟
- `_variant_add_intermediate_output()`：標記中間輸出
- 總共 +160 行

### 輸出檔案

- **dags.json**（7 個 DAG）
  - 38 節點，31 邊，1 個孤立節點（2.6%）

- **augmented_dags.json**（77 個 DAG）
  - 7 個原始 + 70 個變體
  - 11 種增強方法均勻分布

- **toolscale_dataset.json**（77 筆樣本）
  - 420 個 planning 步驟
  - 17 種工具
  - 無 None tool

---

## ✅ 驗證結果

### ✓ 已驗證
- [x] DAG 品質：孤立節點 2.6%，符合預期
- [x] 資料增強：77 個 DAG，11 種方法均勻
- [x] 最終資料集：無 None tool，多樣性 26.0%
- [x] 程式碼：所有新功能都已實作並測試

### ⚠ 待改進（從 GAIA L3 十題分析發現）
- [ ] 覆蓋率低：只有 30%（3/10 題）可執行
- [ ] 正確率低：只有 33.3%（1/3 題）答對
- [ ] 特殊情況：題目 7 完全沒有工具步驟（39 個推理步驟）

---

## 🎓 結論

**用最簡單的話總結**：

昨天做了兩件事：
1. **讓電腦更聰明**：不再傻傻地把所有步驟串成一條線，而是根據「佔位符」「參數」「語義」來判斷誰依賴誰
2. **生出更多訓練資料**：從 7 份原始資料變出 77 份，而且更多樣化

**結果**：
- DAG 的孤立節點從 20% 降到 2.6%（進步 87%）
- 訓練樣本從 42 增加到 77（增加 83%）
- 資料多樣性從 21.4% 提升到 26.0%（進步 22%）

**但仍有問題**：
- GAIA Level 3 的 10 題中，只有 1 題答對
- 覆蓋率和正確率都偏低
- 需要進一步改進 Parser 和工具實作

---

**報告結束**

有任何問題歡迎詢問！
