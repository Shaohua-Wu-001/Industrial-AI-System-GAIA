#!/usr/bin/env python3
"""
GPT-4o-mini æ‰¹æ¬¡åŸ·è¡Œç³»çµ±ï¼ˆä½¿ç”¨æ‚¨çš„ 43 å€‹ GAIA toolsï¼‰

åŸ·è¡Œ 10 é¡Œ GAIA Level 3ï¼Œåˆ†æç­”å°/ç­”éŒ¯

ä½¿ç”¨æ–¹å¼ï¼š
    export OPENAI_API_KEY="sk-..."
    python run_gpt4o_mini.py --limit 10

è¼¸å‡ºï¼š
    - results_gpt4o_mini.jsonï¼ˆå®Œæ•´åŸ·è¡Œè»Œè·¡ï¼‰
    - analysis_summary.jsonï¼ˆç­”å°/ç­”éŒ¯åˆ†æï¼‰
"""

import json
import os
import sys
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import time
import traceback

# å¼•å…¥æ‚¨çš„ 43 å€‹ GAIA functions
import gaia_function

try:
    from openai import OpenAI
except ImportError:
    print("éŒ¯èª¤ï¼šè«‹å®‰è£ OpenAI å¥—ä»¶")
    print("åŸ·è¡Œï¼špip install openai")
    sys.exit(1)


class GAIARunner:
    """GAIA åŸ·è¡Œå™¨ï¼ˆç”¨ GPT-4o-mini + 43 toolsï¼‰"""

    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4o-mini"):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError(
                "æœªè¨­å®š OPENAI_API_KEYï¼\n"
                "è«‹åŸ·è¡Œï¼šexport OPENAI_API_KEY='your-key'"
            )

        self.client = OpenAI(api_key=self.api_key)
        self.model = model

        # è¼‰å…¥è‡ªå‹•ç”Ÿæˆçš„ tools schema
        with open("tools_schema.json", 'r') as f:
            self.tools_schema = json.load(f)

        with open("tools_mapping.json", 'r') as f:
            self.tool_map = json.load(f)

        print(f"âœ“ å·²è¼‰å…¥ {len(self.tools_schema)} å€‹ tools")

    def execute_tool(self, tool_name: str, arguments: Dict) -> Dict:
        """åŸ·è¡Œå–®ä¸€å·¥å…·"""
        try:
            # å–å¾—å¯¦éš›çš„ function
            if tool_name not in self.tool_map:
                return {
                    "success": False,
                    "error": f"æœªçŸ¥å·¥å…·ï¼š{tool_name}"
                }

            func = getattr(gaia_function, tool_name)

            # åŸ·è¡Œ
            result = func(**arguments)

            return {
                "success": True,
                "result": result,
                "error": None
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "traceback": traceback.format_exc()
            }

    def run_single_task(
        self,
        task: Dict,
        max_turns: int = 20,
        timeout: int = 180
    ) -> Dict:
        """åŸ·è¡Œå–®ä¸€é¡Œç›®"""
        task_id = task["task_id"]
        question = task["Question"]
        ground_truth = task["Final answer"]
        file_path = task.get("file_path", "")

        print(f"\n{'='*70}")
        print(f"é¡Œç›®ï¼š{task_id}")
        print(f"å•é¡Œï¼š{question[:80]}...")
        if file_path:
            print(f"æª”æ¡ˆï¼š{file_path}")
        print(f"{'='*70}")

        # æº–å‚™ç³»çµ±æç¤ºè©
        system_prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„å•é¡Œè§£æ±ºåŠ©æ‰‹ã€‚ä½ æœ‰ 43 å€‹å·¥å…·å¯ç”¨ã€‚

å¯ç”¨å·¥å…·é¡åˆ¥ï¼š
- æª”æ¡ˆè®€å–ï¼šread_pdf, read_csv, read_excel, read_json, read_xml, read_docx, read_text_file, read_image
- ç¶²è·¯ï¼šweb_search, web_fetch, wikipedia_search
- è¨ˆç®—ï¼šcalculate, statistical_analysis, correlation_analysis, moving_average
- è³‡æ–™è™•ç†ï¼šfilter_data, sort_data, aggregate_data, join_data, pivot_table
- å­—ä¸²è™•ç†ï¼šregex_search, string_transform, split_join_text, find_in_text
- å…¶ä»–ï¼šextract_zip, date_calculator, currency_converter, geocoding ç­‰

é‡è¦è¦å‰‡ï¼š
1. ä¸€æ­¥ä¸€æ­¥æ€è€ƒï¼Œä½¿ç”¨åˆé©çš„å·¥å…·
2. å¦‚æœæœ‰æª”æ¡ˆè·¯å¾‘ï¼Œå¿…é ˆå…ˆç”¨å°æ‡‰çš„ read_* å·¥å…·è®€å–
3. è¨ˆç®—æ™‚ä½¿ç”¨ calculate å·¥å…·
4. æœ€å¾Œçµ¦å‡ºæ˜ç¢ºçš„æœ€çµ‚ç­”æ¡ˆï¼ˆåªå›ç­”ç­”æ¡ˆæœ¬èº«ï¼Œä¸è¦é¡å¤–è§£é‡‹ï¼‰

æª”æ¡ˆè·¯å¾‘è¦å‰‡ï¼š
- å¦‚æœé¡Œç›®æåˆ°æª”æ¡ˆï¼Œè·¯å¾‘åœ¨ data/ è³‡æ–™å¤¾ä¸‹
- å®Œæ•´è·¯å¾‘ï¼šdata/{file_path}
"""

        # å»ºæ§‹ä½¿ç”¨è€…å•é¡Œ
        user_message = question
        if file_path:
            user_message += f"\n\næª”æ¡ˆä½æ–¼ï¼šdata/{file_path}"

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]

        execution_trace = []
        start_time = time.time()

        for turn in range(max_turns):
            if time.time() - start_time > timeout:
                return {
                    "task_id": task_id,
                    "success": False,
                    "error": "åŸ·è¡Œè¶…æ™‚",
                    "ground_truth": ground_truth,
                    "predicted": None,
                    "execution_trace": execution_trace,
                    "turns": turn,
                    "elapsed_time": time.time() - start_time
                }

            try:
                # å‘¼å« GPT-4o-mini
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    tools=self.tools_schema,
                    tool_choice="auto",
                    temperature=0.0
                )

                assistant_message = response.choices[0].message
                messages.append(assistant_message)

                # æª¢æŸ¥æ˜¯å¦æœ‰ tool calls
                if not assistant_message.tool_calls:
                    # æœ€çµ‚ç­”æ¡ˆ
                    final_answer = assistant_message.content.strip()

                    execution_trace.append({
                        "turn": turn,
                        "type": "final_answer",
                        "content": final_answer
                    })

                    # ç°¡å–®çš„ç­”æ¡ˆé©—è­‰
                    predicted = final_answer
                    correct = self._check_answer(predicted, ground_truth)

                    return {
                        "task_id": task_id,
                        "success": True,
                        "ground_truth": ground_truth,
                        "predicted": predicted,
                        "correct": correct,
                        "execution_trace": execution_trace,
                        "turns": turn + 1,
                        "elapsed_time": time.time() - start_time
                    }

                # åŸ·è¡Œ tool calls
                for tool_call in assistant_message.tool_calls:
                    tool_name = tool_call.function.name
                    tool_args = json.loads(tool_call.function.arguments)

                    print(f"  [{turn}] ğŸ”§ {tool_name}({json.dumps(tool_args, ensure_ascii=False)[:60]}...)")

                    # åŸ·è¡Œ
                    tool_result = self.execute_tool(tool_name, tool_args)

                    if tool_result["success"]:
                        print(f"       âœ“ æˆåŠŸ")
                    else:
                        print(f"       âœ— å¤±æ•—ï¼š{tool_result['error'][:50]}...")

                    execution_trace.append({
                        "turn": turn,
                        "type": "tool_call",
                        "tool_name": tool_name,
                        "arguments": tool_args,
                        "result": tool_result
                    })

                    # å‚³å›çµæœ
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": json.dumps(tool_result, ensure_ascii=False)
                    })

            except Exception as e:
                print(f"  âœ— éŒ¯èª¤ï¼š{str(e)}")
                execution_trace.append({
                    "turn": turn,
                    "type": "error",
                    "error": str(e)
                })

                return {
                    "task_id": task_id,
                    "success": False,
                    "error": str(e),
                    "ground_truth": ground_truth,
                    "predicted": None,
                    "correct": False,
                    "execution_trace": execution_trace,
                    "turns": turn
                }

        # é”åˆ°æœ€å¤§è¼ªæ•¸
        return {
            "task_id": task_id,
            "success": False,
            "error": "é”åˆ°æœ€å¤§è¼ªæ•¸",
            "ground_truth": ground_truth,
            "predicted": None,
            "correct": False,
            "execution_trace": execution_trace,
            "turns": max_turns
        }

    def _check_answer(self, predicted: str, ground_truth: str) -> bool:
        """ç°¡å–®çš„ç­”æ¡ˆæ¯”å°"""
        pred = predicted.lower().strip()
        gt = ground_truth.lower().strip()

        # å®Œå…¨åŒ¹é…
        if pred == gt:
            return True

        # åŒ…å«åŒ¹é…
        if gt in pred or pred in gt:
            return True

        # æ•¸å­—åŒ¹é…ï¼ˆå…è¨±å°èª¤å·®ï¼‰
        try:
            pred_num = float(pred)
            gt_num = float(gt)
            return abs(pred_num - gt_num) < 0.01
        except:
            pass

        return False

    def analyze_results(self, results: List[Dict]) -> Dict:
        """åˆ†æåŸ·è¡Œçµæœ"""
        total = len(results)
        correct = sum(1 for r in results if r.get("correct"))
        incorrect = total - correct

        correct_tasks = [r["task_id"] for r in results if r.get("correct")]
        incorrect_tasks = [
            {
                "task_id": r["task_id"],
                "ground_truth": r["ground_truth"],
                "predicted": r.get("predicted"),
                "error": r.get("error")
            }
            for r in results if not r.get("correct")
        ]

        return {
            "summary": {
                "total": total,
                "correct": correct,
                "incorrect": incorrect,
                "accuracy": correct / total if total > 0 else 0
            },
            "correct_tasks": correct_tasks,
            "incorrect_tasks": incorrect_tasks
        }


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--limit", type=int, default=10, help="åŸ·è¡Œé¡Œç›®æ•¸é‡ï¼ˆé è¨­ 10ï¼‰")
    parser.add_argument("--model", type=str, default="gpt-4o-mini", help="æ¨¡å‹")
    parser.add_argument("--max-turns", type=int, default=20, help="æœ€å¤§è¼ªæ•¸")

    args = parser.parse_args()

    # è¼‰å…¥é¡Œç›®
    with open("gaia_level3_tasks.json", 'r') as f:
        tasks = json.load(f)

    print(f"\nè¼‰å…¥ {len(tasks)} é¡Œ GAIA Level 3")
    print(f"åŸ·è¡Œå‰ {args.limit} é¡Œ\n")

    # åˆå§‹åŒ–
    try:
        runner = GAIARunner(model=args.model)
    except ValueError as e:
        print(f"éŒ¯èª¤ï¼š{e}")
        sys.exit(1)

    # åŸ·è¡Œ
    results = []
    for i, task in enumerate(tasks[:args.limit], 1):
        print(f"\n{'#'*70}")
        print(f"# é€²åº¦ï¼š{i}/{args.limit}")
        print(f"{'#'*70}")

        result = runner.run_single_task(task, max_turns=args.max_turns)
        results.append(result)

        # å³æ™‚å„²å­˜
        with open("results_gpt4o_mini.json", 'w') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

    # åˆ†æ
    analysis = runner.analyze_results(results)

    with open("analysis_summary.json", 'w') as f:
        json.dump(analysis, f, indent=2, ensure_ascii=False)

    # é¡¯ç¤ºçµæœ
    print(f"\n{'='*70}")
    print(f"åŸ·è¡Œå®Œæˆï¼")
    print(f"{'='*70}")
    print(f"ç¸½é¡Œæ•¸ï¼š{analysis['summary']['total']}")
    print(f"ç­”å°ï¼š{analysis['summary']['correct']}")
    print(f"ç­”éŒ¯ï¼š{analysis['summary']['incorrect']}")
    print(f"æ­£ç¢ºç‡ï¼š{analysis['summary']['accuracy']*100:.1f}%")
    print(f"\nç­”å°é¡Œç›®ï¼š{', '.join(analysis['correct_tasks'])}")
    print(f"\nçµæœå·²å„²å­˜è‡³ï¼šresults_gpt4o_mini.json")
    print(f"åˆ†æå·²å„²å­˜è‡³ï¼šanalysis_summary.json")


if __name__ == "__main__":
    main()
